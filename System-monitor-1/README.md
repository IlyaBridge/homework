#  «Создание собственных модулей» "`«Системы мониторинга»`" - `Казначеев Илья`

https://github.com/LotsmanSM/DevOps-35-Netology/blob/main/devops-05-ci/ci-05-teamcity/README.md

---

## Задание 1
Вас пригласили настроить мониторинг на проект. На онбординге вам рассказали, что проект представляет из себя платформу для вычислений с выдачей текстовых отчетов, которые сохраняются на диск. Взаимодействие с платформой осуществляется по протоколу http. Также вам отметили, что вычисления загружают ЦПУ. Какой минимальный набор метрик вы выведите в мониторинг и почему?

## Решение 1
На мой взгляд минимальный набор метрик:
- CPU Usage – нагрузка на процессор (т.к. вычисления ресурсоемки).
- HTTP Request Rate/Latency – доступность сервиса и время ответа.
- Disk I/O – запись отчетов на диск.
- Memory Usage – контроль утечек RAM.
- Error Rate (5xx/4xx) – статусы HTTP-ответов.
Данные метрики охватывают критичные для работы компоненты (производительность, доступность, сохранение данных).

---

## Задание 2
Менеджер продукта посмотрев на ваши метрики сказал, что ему непонятно что такое RAM/inodes/CPUla. Также он сказал, что хочет понимать, насколько мы выполняем свои обязанности перед клиентами и какое качество обслуживания. Что вы можете ему предложить?

## Решение 2
Перевести метрики в бизнес-показатели:
- SLA (% доступности сервиса).
- SLO (например, "95% запросов выполняются <1 сек").
- User Satisfaction Score (на основе HTTP-ошибок).

Визуализировать в Grafana дашборды с понятными графиками:
- "Доступность сервиса: 99.9%".
- "Среднее время ответа: 500 мс".

---

## Задание 3
Вашей DevOps команде в этом году не выделили финансирование на построение системы сбора логов. Разработчики в свою очередь хотят видеть все ошибки, которые выдают их приложения. Какое решение вы можете предпринять в этой ситуации, чтобы разработчики получали ошибки приложения?

## Решение 3
Бесплатные решения:
- Fluentd + Elasticsearch (или Loki) – сбор логов в открытые СУБД.
- Sentry – отправка ошибок в Slack/Email.
- Graylog – локальный сервер для агрегации логов.
Использование систем журналирования ОС (например, journald для Linux).

---

## Задание 4
Вы, как опытный SRE, сделали мониторинг, куда вывели отображения выполнения SLA=99% по http кодам ответов. Вычисляете этот параметр по следующей формуле: summ_2xx_requests/summ_all_requests. Данный параметр не поднимается выше 70%, но при этом в вашей системе нет кодов ответа 5xx и 4xx. Где у вас ошибка?

## Решение 4
Ошибка в формуле:
В расчете SLA учитываются только 2xx, но не 3xx (редиректы).

Должно быть так:
SLA = (summ_2xx_requests + summ_3xx_requests) / summ_all_requests

---

## Задание 5
Опишите основные плюсы и минусы pull и push систем мониторинга.

## Решение 5

### Push-модель
Плюсы:
Простота масштабирования – сервер не должен знать обо всех агентах.
Гибкость – можно отправлять метрики из любых источников (даже из скриптов).
Работает за NAT/Firewall – агенты инициируют соединение.
Подходит для кратковременных задач – например, сбор данных от serverless-функций.

Минусы:
Риск потери данных – если сервер перегружен, метрики могут теряться.
Сложность отладки – трудно понять, почему данные не дошли.
Нет контроля над частотой сбора – агенты могут завалить сервер запросами.

### Pull-модель
Плюсы:
Контроль над сбором – сервер сам решает, когда и какие метрики собирать.
Надежность – данные не теряются, даже если агент временно недоступен.
Экономия ресурсов – запросы выполняются по расписанию, нет лишней нагрузки.
Проще детектировать проблемы агентов – если агент не отвечает, это сразу видно.

Минусы:
Требует открытых портов – агенты должны быть доступны для опроса.
Сложность в динамических средах – нужен механизм обнаружения новых сервисов (например, Service Discovery).
Задержки данных – метрики обновляются только при опросе.

---

## Задание 6
Какие из ниже перечисленных систем относятся к push модели, а какие к pull? А может есть гибридные?
Prometheus
TICK
Zabbix
VictoriaMetrics
Nagios

## Решение 6
Push: TICK (Telegraf), Zabbix (гибрид), Nagios (гибрид).
Pull: Prometheus, VictoriaMetrics.

---
## Задание 7
Склонируйте себе репозиторий (https://github.com/influxdata/sandbox/tree/master) и запустите TICK-стэк, используя технологии docker и docker-compose.
В виде решения на это упражнение приведите скриншот веб-интерфейса ПО chronograf (http://localhost:8888).
P.S.: если при запуске некоторые контейнеры будут падать с ошибкой - проставьте им режим Z, например ./data:/var/lib:Z

## Решение 7



---

## Задание 8
8. Перейдите в веб-интерфейс Chronograf (http://localhost:8888) и откройте вкладку Data explorer.
Нажмите на кнопку Add a query
Изучите вывод интерфейса и выберите БД telegraf.autogen
В measurments выберите cpu->host->telegraf-getting-started, а в fields выберите usage_system. Внизу появится график утилизации cpu.
Вверху вы можете увидеть запрос, аналогичный SQL-синтаксису. Поэкспериментируйте с запросом, попробуйте изменить группировку и интервал наблюдений.
Для выполнения задания приведите скриншот с отображением метрик утилизации cpu из веб-интерфейса.

## Решение 8



---
## Задание 9
Изучите список telegraf inputs (https://github.com/influxdata/telegraf/tree/master/plugins/inputs). Добавьте в конфигурацию telegraf следующий плагин - docker:
[[inputs.docker]]
  endpoint = "unix:///var/run/docker.sock"
Дополнительно вам может потребоваться донастройка контейнера telegraf в docker-compose.yml дополнительного volume и режима privileged:

```
  telegraf:
    image: telegraf:1.4.0
    privileged: true
    volumes:
      - ./etc/telegraf.conf:/etc/telegraf/telegraf.conf:Z
      - /var/run/docker.sock:/var/run/docker.sock:Z
    links:
      - influxdb
    ports:
      - "8092:8092/udp"
      - "8094:8094"
      - "8125:8125/udp"
```

После настройке перезапустите telegraf, обновите веб интерфейс и приведите скриншотом список measurments в веб-интерфейсе базы telegraf.autogen . Там должны появиться метрики, связанные с docker.
Факультативно можете изучить какие метрики собирает telegraf после выполнения данного задания.

## Решение 9




---